# Agent-OS-Kernel é…ç½®æ–‡ä»¶
# å‚è€ƒ AIOS è®¾è®¡

# API Keys (å»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡)
api_keys:
  # å›½å¤–æ¨¡å‹
  openai: "${OPENAI_API_KEY}"          # OpenAI API Key
  anthropic: "${ANTHROPIC_API_KEY}"    # Anthropic API Key
  groq: "${GROQ_API_KEY}"             # Groq API Key
  huggingface: "${HF_AUTH_TOKEN}"      # HuggingFace Token
  
  # ğŸ‡¨ğŸ‡³ ä¸­å›½æ¨¡å‹
  deepseek: "${DEEPSEEK_API_KEY}"       # DeepSeek API Key
  kimi: "${KIMI_API_KEY}"             # Kimi (Moonshot AI) API Key
  minimax: "${MINIMAX_API_KEY}"        # MiniMax API Key
  qwen: "${DASHSCOPE_API_KEY}"         # é˜¿é‡Œäº‘é€šä¹‰åƒé—® API Key

# LLM Models é…ç½®
llms:
  models:
    # ğŸ‡¨ğŸ‡³ ä¸­å›½æ¨¡å‹ (é»˜è®¤æ¨è)
    - name: "deepseek-chat"
      provider: "deepseek"
      description: "DeepSeek Chat (æ€§ä»·æ¯”é«˜)"
      max_tokens: 8192
      temperature: 0.7
    
    - name: "deepseek-reasoner"
      provider: "deepseek"
      description: "DeepSeek Reasoner (æ¨ç†å¢å¼º)"
      max_tokens: 8192
      temperature: 0.3
    
    - name: "qwen-turbo"
      provider: "qwen"
      description: "é€šä¹‰åƒé—® Turbo (å¿«é€Ÿå“åº”)"
      max_tokens: 8192
      temperature: 0.7
    
    - name: "qwen-plus"
      provider: "qwen"
      description: "é€šä¹‰åƒé—® Plus (å¹³è¡¡æ€§èƒ½)"
      max_tokens: 16384
      temperature: 0.7
    
    - name: "qwen-max"
      provider: "qwen"
      description: "é€šä¹‰åƒé—® Max (æœ€å¼ºæ€§èƒ½)"
      max_tokens: 16384
      temperature: 0.7
    
    - name: "moonshot-v1-8k"
      provider: "kimi"
      description: "Kimi 8K ä¸Šä¸‹æ–‡"
      max_tokens: 8192
      temperature: 0.7
    
    - name: "moonshot-v1-32k"
      provider: "kimi"
      description: "Kimi 32K ä¸Šä¸‹æ–‡"
      max_tokens: 32768
      temperature: 0.7
    
    - name: "abab6.5s-chat"
      provider: "minimax"
      description: "MiniMax èŠå¤©æ¨¡å‹"
      max_tokens: 16384
      temperature: 0.7
    
    # ğŸŒ å›½å¤–æ¨¡å‹
    - name: "gpt-4o"
      provider: "openai"
      description: "GPT-4o (å¤šæ¨¡æ€)"
      max_tokens: 8192
      temperature: 0.7
    
    - name: "gpt-4o-mini"
      provider: "openai"
      description: "GPT-4o-mini (å¿«é€Ÿä¾¿å®œ)"
      max_tokens: 4096
      temperature: 0.7
    
    - name: "claude-sonnet-4-20250514"
      provider: "anthropic"
      description: "Claude Sonnet 4"
      max_tokens: 8192
      temperature: 0.7
    
    - name: "llama-3.3-70b-versatile"
      provider: "groq"
      description: "Llama 3 (é«˜é€Ÿæ¨ç†)"
      max_tokens: 8192
      temperature: 0.7
    
    # ğŸ  æœ¬åœ°æ¨¡å‹
    - name: "qwen2.5:7b"
      provider: "ollama"
      description: "Qwen 2.5 æœ¬åœ°æ¨¡å‹"
      base_url: "http://localhost:11434"
      max_tokens: 4096
      temperature: 0.7
    
    - name: "meta-llama/Llama-3.1-8B-Instruct"
      provider: "vllm"
      description: "Llama 3.1 8B (vLLM)"
      base_url: "http://localhost:8000/v1"
      max_tokens: 4096
      temperature: 0.7

# é»˜è®¤æ¨¡å‹ (æ¨èä¸­å›½æ¨¡å‹)
default_model: "deepseek-chat"

# Server é…ç½®
server:
  host: "0.0.0.0"
  port: 8000
  workers: 1
  reload: false

# Database é…ç½® (PostgreSQL)
database:
  host: "localhost"
  port: 5432
  username: "postgres"
  password: "${POSTGRES_PASSWORD}"
  name: "agent_os_kernel"
  pool_size: 10
  max_overflow: 20

# Redis é…ç½®
redis:
  host: "localhost"
  port: 6379
  db: 0

# Vector Store é…ç½® (pgvector)
vector:
  enabled: true
  dimension: 1536
  metric: "cosine"

# Agent é…ç½®
agents:
  max_concurrent: 10
  default_timeout: 300
  max_memory_pages: 100
  max_tools_per_agent: 50

# å·¥å…·é…ç½®
tools:
  max_execution_time: 60

# è°ƒåº¦é…ç½®
scheduler:
  type: "fifo"
  quantum: 5.0
  max_queue_size: 100

# ç›‘æ§é…ç½®
monitoring:
  metrics_enabled: true
  health_check_interval: 30
  log_level: "INFO"

# å®‰å…¨é…ç½®
security:
  rate_limit:
    enabled: true
    requests_per_minute: 60
  cors:
    enabled: true
    origins:
      - "http://localhost:3000"
      - "http://localhost:8080"

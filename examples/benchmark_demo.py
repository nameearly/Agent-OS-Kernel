# -*- coding: utf-8 -*-
"""
Benchmark Demo - Agent-OS-Kernel æ€§èƒ½åŸºå‡†æµ‹è¯•æ¼”ç¤º

æ¼”ç¤ºæ€§èƒ½æµ‹è¯•å·¥å…·å’Œä¼˜åŒ–å™¨çš„ä½¿ç”¨æ–¹æ³•ã€‚
"""

import time
import random
from typing import Dict, Any
from agent_os_kernel.core.benchmark import (
    LatencyBenchmark,
    ThroughputBenchmark,
    ResourceMonitor,
    PerformanceReport,
    PerformanceBenchmark,
    LatencyResult,
    ThroughputResult,
    ResourceUsage,
)
from agent_os_kernel.core.optimizer import (
    ConnectionPool,
    LRUCache,
    ThreadPoolOptimizer,
    MemoryOptimizer,
    ConcurrencyLimiter,
    BatchProcessor,
    PoolConfig,
    CacheConfig,
    ConcurrencyConfig,
)


def demo_latency_measurement():
    """æ¼”ç¤ºå»¶è¿Ÿæµ‹é‡"""
    print("\n" + "=" * 60)
    print("ğŸ“Š å»¶è¿Ÿæµ‹é‡æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºåŸºå‡†æµ‹è¯•å™¨
    benchmark = LatencyBenchmark(warmup_iterations=5)
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„å‡½æ•°
    def fast_operation():
        return sum(range(100))
    
    def medium_operation():
        time.sleep(0.001)
        data = [i * 2 for i in range(1000)]
        return sum(data)
    
    def slow_operation():
        time.sleep(0.005)
        result = 0
        for i in range(10000):
            result += i ** 2
        return result
    
    # æµ‹é‡å„ä¸ªå‡½æ•°
    for name, func in [
        ("å¿«é€Ÿæ“ä½œ", fast_operation),
        ("ä¸­ç­‰æ“ä½œ", medium_operation),
        ("æ…¢é€Ÿæ“ä½œ", slow_operation),
    ]:
        print(f"\næµ‹è¯•: {name}")
        result = benchmark.measure(func, iterations=20, warmup=True)
        
        print(f"  å¹³å‡å»¶è¿Ÿ: {result.mean_ms:.4f}ms")
        print(f"  P95å»¶è¿Ÿ:  {result.p95_ms:.4f}ms")
        print(f"  P99å»¶è¿Ÿ:  {result.p99_ms:.4f}ms")
        print(f"  æ ‡å‡†å·®:   {result.std_dev_ms:.4f}ms")


def demo_throughput_measurement():
    """æ¼”ç¤ºååé‡æµ‹é‡"""
    print("\n" + "=" * 60)
    print("ğŸ“ˆ ååé‡æµ‹é‡æ¼”ç¤º")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„å¤„ç†å‡½æ•°
    def process_item(item: int) -> Dict[str, int]:
        return {"processed": item, "value": item * 2}
    
    # å•çº¿ç¨‹ååé‡
    print("\nå•çº¿ç¨‹ååé‡æµ‹è¯•:")
    single_benchmark = ThroughputBenchmark(max_workers=1)
    result = single_benchmark.measure(
        lambda: process_item(random.randint(0, 1000)),
        total_operations=100,
        concurrency=1
    )
    
    print(f"  æ€»æ“ä½œæ•°:   {result.total_operations}")
    print(f"  æˆåŠŸæ•°:     {result.success_count}")
    print(f"  æ€»è€—æ—¶:     {result.total_time_ms:.2f}ms")
    print(f"  ååé‡:     {result.operations_per_second:.2f} ops/s")
    print(f"  å¹³å‡å»¶è¿Ÿ:   {result.avg_latency_ms:.4f}ms")
    
    # å¹¶å‘ååé‡
    print("\nå¹¶å‘ååé‡æµ‹è¯•:")
    concurrent_benchmark = ThroughputBenchmark(max_workers=4)
    result = concurrent_benchmark.measure(
        lambda: process_item(random.randint(0, 1000)),
        total_operations=200,
        concurrency=4
    )
    
    print(f"  æ€»æ“ä½œæ•°:   {result.total_operations}")
    print(f"  ååé‡:     {result.operations_per_second:.2f} ops/s")


def demo_resource_monitoring():
    """æ¼”ç¤ºèµ„æºç›‘æ§"""
    print("\n" + "=" * 60)
    print("ğŸ’» èµ„æºä½¿ç”¨ç›‘æ§æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºç›‘æ§å™¨
    monitor = ResourceMonitor(sample_interval=0.05)
    
    # æ•è·åŸºå‡†èµ„æºä½¿ç”¨
    print("\nç©ºé—²çŠ¶æ€èµ„æºä½¿ç”¨:")
    baseline = monitor.capture()
    print(f"  CPU: {baseline.cpu_percent:.1f}%")
    print(f"  å†…å­˜: {baseline.memory_mb:.2f} MB")
    
    # å¯åŠ¨ç›‘æ§å¹¶è¿›è¡Œä¸€äº›æ“ä½œ
    print("\nç›‘æ§é«˜è´Ÿè½½çŠ¶æ€...")
    monitor.start(duration_seconds=2.0)
    
    # æ¨¡æ‹Ÿä¸€äº›CPUå¯†é›†å‹æ“ä½œ
    def cpu_intensive_task():
        start = time.time()
        while time.time() - start < 0.1:
            sum(i ** 2 for i in range(10000))
    
    benchmark = ThroughputBenchmark(max_workers=2)
    benchmark.measure(cpu_intensive_task, total_operations=20, concurrency=2)
    
    # è·å–ç›‘æ§ç»Ÿè®¡
    stats = monitor.get_stats()
    
    print(f"\nç›‘æ§æœŸé—´ç»Ÿè®¡:")
    print(f"  é‡‡æ ·æ•°: {stats['samples_count']}")
    print(f"  CPU å¹³å‡: {stats['cpu_percent']['mean']:.1f}%")
    print(f"  CPU æœ€å¤§: {stats['cpu_percent']['max']:.1f}%")
    print(f"  å†…å­˜å¹³å‡: {stats['memory_mb']['mean']:.2f} MB")
    print(f"  å†…å­˜æœ€å¤§: {stats['memory_mb']['max']:.2f} MB")


def demo_performance_report():
    """æ¼”ç¤ºæ€§èƒ½æŠ¥å‘Šç”Ÿæˆ"""
    print("\n" + "=" * 60)
    print("ğŸ“ æ€§èƒ½æŠ¥å‘Šç”Ÿæˆæ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºç»¼åˆåŸºå‡†æµ‹è¯•
    benchmark = PerformanceBenchmark(iterations=50)
    
    def test_function_1():
        return sum(i * 2 for i in range(500))
    
    def test_function_2():
        time.sleep(0.001)
        return [i ** 2 for i in range(200)]
    
    # è¿è¡Œå¯¹æ¯”æµ‹è¯•
    results = benchmark.run_comparison({
        "å¿«é€Ÿæ±‚å’Œ": test_function_1,
        "å¸¦å»¶è¿Ÿåˆ—è¡¨": test_function_2,
    })
    
    # ç”ŸæˆæŠ¥å‘Š
    report = PerformanceReport("æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š")
    
    report.add_section("æµ‹è¯•è¯´æ˜", {
        "iterations": 50,
        "warmup": True,
    })
    
    for name, data in results["results"].items():
        report.add_latency_result(f"{name}_latency", LatencyResult(**data["latency"]))
    
    report.add_section("æœ€ä½³æ€§èƒ½", results["best_latency"])
    
    # ç”Ÿæˆå¹¶æ˜¾ç¤ºæ–‡æœ¬æŠ¥å‘Š
    print("\nç”Ÿæˆçš„æ€§èƒ½æŠ¥å‘Š:")
    print("-" * 40)
    print(report.generate_text())
    
    # ä¿å­˜æŠ¥å‘Š
    print("\næŠ¥å‘Šå·²ç”Ÿæˆï¼Œå¯ä»¥è°ƒç”¨ report.save() ä¿å­˜åˆ°æ–‡ä»¶ã€‚")


def demo_optimizer_connection_pool():
    """æ¼”ç¤ºè¿æ¥æ± ä¼˜åŒ–"""
    print("\n" + "=" * 60)
    print("ğŸ”„ è¿æ¥æ± ä¼˜åŒ–æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿè¿æ¥å·¥å‚
    connection_id = {"counter": 0}
    
    def create_connection():
        connection_id["counter"] += 1
        return {"id": connection_id["counter"], "created_at": time.time()}
    
    # åˆ›å»ºè¿æ¥æ± 
    config = PoolConfig(min_size=2, max_size=5, checkout_timeout=5.0)
    pool = ConnectionPool(create_connection, config)
    
    print(f"\nè¿æ¥æ± åˆå§‹çŠ¶æ€: {pool.status()}")
    
    # è·å–å¹¶ä½¿ç”¨è¿æ¥
    conn1 = pool.acquire()
    print(f"è·å–è¿æ¥1: {conn1}")
    
    conn2 = pool.acquire()
    print(f"è·å–è¿æ¥2: {conn2}")
    
    print(f"è·å–åçŠ¶æ€: {pool.status()}")
    
    # é‡Šæ”¾è¿æ¥
    pool.release(conn1)
    pool.release(conn2)
    
    print(f"é‡Šæ”¾åçŠ¶æ€: {pool.status()}")
    
    # å…³é—­è¿æ¥æ± 
    pool.close()
    print("è¿æ¥æ± å·²å…³é—­")


def demo_optimizer_lru_cache():
    """æ¼”ç¤ºLRUç¼“å­˜ä¼˜åŒ–"""
    print("\n" + "=" * 60)
    print("ğŸ’¾ LRUç¼“å­˜ä¼˜åŒ–æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºç¼“å­˜
    config = CacheConfig(max_size=5, ttl_seconds=10.0)
    cache = LRUCache(config)
    cache.start()
    
    # æ·»åŠ ç¼“å­˜é¡¹
    print("\næ·»åŠ ç¼“å­˜é¡¹:")
    for i in range(6):
        cache.set(f"key_{i}", f"value_{i}")
        print(f"  è®¾ç½® key_{i} = value_{i}")
    
    # æ£€æŸ¥è‡ªåŠ¨æ·˜æ±°
    print(f"\nç¼“å­˜ç»Ÿè®¡: {cache.stats()}")
    
    # è®¿é—®ç¼“å­˜é¡¹ï¼ˆè§¦å‘LRUï¼‰
    print(f"\nè®¿é—® key_0 (è§¦å‘LRUç§»åŠ¨)")
    value = cache.get("key_0")
    print(f"  è·å– key_0: {value}")
    
    # æ·»åŠ æ–°é¡¹è§¦å‘æ·˜æ±°
    print("\næ·»åŠ æ–°é¡¹ key_6 (è§¦å‘LRUæ·˜æ±°)")
    cache.set("key_6", "value_6")
    
    print(f"ç¼“å­˜ç»Ÿè®¡: {cache.stats()}")
    
    # åœæ­¢ç¼“å­˜
    cache.stop()


def demo_optimizer_thread_pool():
    """æ¼”ç¤ºçº¿ç¨‹æ± ä¼˜åŒ–"""
    print("\n" + "=" * 60)
    print("ğŸ§µ çº¿ç¨‹æ± ä¼˜åŒ–æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºçº¿ç¨‹æ± 
    config = ConcurrencyConfig(max_workers=2, queue_size=10)
    pool = ThreadPoolOptimizer(config)
    
    print(f"\nçº¿ç¨‹æ± çŠ¶æ€: {pool.stats()}")
    
    # æäº¤ä»»åŠ¡
    def task(task_id: int) -> str:
        time.sleep(0.05)
        return f"task_{task_id}_completed"
    
    print("\næäº¤ä»»åŠ¡:")
    for i in range(3):
        success = pool.submit(f"task_{i}", task, i)
        print(f"  æäº¤ task_{i}: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
    
    print(f"æäº¤åçŠ¶æ€: {pool.stats()}")
    
    # è·å–ç»“æœ
    for i in range(3):
        result = pool.get_result(f"task_{i}", timeout=2.0)
        print(f"  è·å– task_{i}: {result}")
    
    # å…³é—­çº¿ç¨‹æ± 
    pool.shutdown()
    print("\nçº¿ç¨‹æ± å·²å…³é—­")


def demo_optimizer_memory_pool():
    """æ¼”ç¤ºå†…å­˜ä¼˜åŒ–"""
    print("\n" + "=" * 60)
    print("ğŸ§  å†…å­˜ä¼˜åŒ–æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºå†…å­˜æ± 
    pool = MemoryOptimizer(max_pool_size=10)
    
    # åˆ›å»ºå¯¹è±¡å·¥å‚
    object_counter = {"counter": 0}
    
    def create_object(value: int):
        object_counter["counter"] += 1
        return {"id": object_counter["counter"], "value": value}
    
    print("\nä½¿ç”¨å†…å­˜æ± :")
    
    # è·å–å¯¹è±¡
    for i in range(5):
        obj = pool.get_or_create(f"type_{i % 2}", lambda: create_object(i))
        print(f"  è·å–å¯¹è±¡: {obj}")
        pool.release(f"type_{i % 2}", obj)
    
    print(f"\nå†…å­˜æ± ç»Ÿè®¡: {pool.get_stats()}")
    
    # æ¸…ç©ºæ± 
    pool.clear_all_pools()
    print("æ‰€æœ‰æ± å·²æ¸…ç©º")


def demo_concurrency_limiter():
    """æ¼”ç¤ºå¹¶å‘é™åˆ¶å™¨"""
    print("\n" + "=" * 60)
    print("ğŸš¦ å¹¶å‘é™åˆ¶å™¨æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºé™åˆ¶å™¨
    limiter = ConcurrencyLimiter(max_concurrent=2)
    
    def critical_section(task_id: int):
        with limiter.limit():
            print(f"  ä»»åŠ¡ {task_id} è¿›å…¥ä¸´ç•ŒåŒº")
            time.sleep(0.1)
            print(f"  ä»»åŠ¡ {task_id} ç¦»å¼€ä¸´ç•ŒåŒº")
            return task_id
    
    print("\nå¹¶å‘æ‰§è¡Œä»»åŠ¡ (æœ€å¤§2ä¸ªå¹¶å‘):")
    
    # æäº¤å¤šä¸ªä»»åŠ¡
    results = []
    for i in range(4):
        result = limiter.limit()
        # æ¨¡æ‹Ÿä»»åŠ¡
        critical_section(i)
    
    print(f"\nå¹¶å‘é™åˆ¶å™¨çŠ¶æ€: {limiter.stats()}")


def demo_batch_processor():
    """æ¼”ç¤ºæ‰¹å¤„ç†å™¨"""
    print("\n" + "=" * 60)
    print("ğŸ“¦ æ‰¹å¤„ç†å™¨æ¼”ç¤º")
    print("=" * 60)
    
    processed_batches = []
    
    def batch_processor(items: list):
        processed_batches.append({
            "count": len(items),
            "timestamp": time.time(),
            "items": items[:3],  # åªä¿ç•™å‰3ä¸ªç¤ºä¾‹
        })
    
    # åˆ›å»ºæ‰¹å¤„ç†å™¨
    processor = BatchProcessor(
        batch_size=5,
        flush_interval=1.0,
        processor=batch_processor
    )
    
    processor.start()
    
    print("\næ·»åŠ é¡¹ç›®åˆ°æ‰¹æ¬¡:")
    for i in range(12):
        success = processor.add(f"item_{i}")
        status = "âœ“" if success else "âœ— (é˜Ÿåˆ—æ»¡)"
        print(f"  æ·»åŠ  item_{i}: {status}")
    
    print(f"\næ‰¹å¤„ç†å™¨ç»Ÿè®¡: {processor.stats()}")
    
    # åœæ­¢å¤„ç†å™¨
    processor.stop(timeout=2.0)
    
    print(f"\nå¤„ç†çš„æ‰¹æ¬¡æ•°: {len(processed_batches)}")
    for batch in processed_batches:
        print(f"  æ‰¹æ¬¡: {batch['count']} ä¸ªé¡¹ç›®")


def demo_comparison_before_after():
    """æ¼”ç¤ºä¼˜åŒ–å‰åçš„å¯¹æ¯”"""
    print("\n" + "=" * 60)
    print("ğŸ“Š ä¼˜åŒ–æ•ˆæœå¯¹æ¯”æ¼”ç¤º")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
    class OldDatabase:
        """æ—§ç‰ˆæ•°æ®åº“ï¼ˆæ— ä¼˜åŒ–ï¼‰"""
        
        def query(self, sql: str):
            # æ¨¡æ‹Ÿæ•°æ®åº“å»¶è¿Ÿ
            time.sleep(0.01)
            return [{"id": 1, "data": "result"}]
    
    class OptimizedDatabase:
        """ä¼˜åŒ–ç‰ˆæ•°æ®åº“ï¼ˆä½¿ç”¨è¿æ¥æ± ï¼‰"""
        
        def __init__(self):
            self.pool = ConnectionPool(
                lambda: {"id": 0, "connected": True},
                PoolConfig(min_size=2, max_size=5)
            )
        
        def query(self, sql: str):
            conn = self.pool.acquire()
            try:
                time.sleep(0.001)  # ä¼˜åŒ–åå»¶è¿Ÿé™ä½
                return [{"id": 1, "data": "result", "conn": conn["id"]}]
            finally:
                self.pool.release(conn)
        
        def close(self):
            self.pool.close()
    
    # æµ‹è¯•æ—§ç‰ˆæœ¬
    print("\næµ‹è¯•æ—§ç‰ˆæ•°æ®åº“ (æ— è¿æ¥æ± ):")
    old_db = OldDatabase()
    benchmark = LatencyBenchmark(warmup_iterations=0)
    old_result = benchmark.measure(
        lambda: old_db.query("SELECT * FROM users"),
        iterations=20, warmup=False
    )
    print(f"  å¹³å‡å»¶è¿Ÿ: {old_result.mean_ms:.4f}ms")
    
    # æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬
    print("\næµ‹è¯•ä¼˜åŒ–ç‰ˆæ•°æ®åº“ (è¿æ¥æ± ):")
    new_db = OptimizedDatabase()
    new_result = benchmark.measure(
        lambda: new_db.query("SELECT * FROM users"),
        iterations=20, warmup=False
    )
    print(f"  å¹³å‡å»¶è¿Ÿ: {new_result.mean_ms:.4f}ms")
    
    # è®¡ç®—æ”¹è¿›
    improvement = (old_result.mean_ms - new_result.mean_ms) / old_result.mean_ms * 100
    print(f"\næ€§èƒ½æ”¹è¿›: {improvement:.1f}%")
    print(f"å»¶è¿Ÿé™ä½: {old_result.mean_ms - new_result.mean_ms:.4f}ms")
    
    new_db.close()


def main():
    """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    print("\n" + "ğŸŒŸ" * 30)
    print("Agent-OS-Kernel æ€§èƒ½åŸºå‡†æµ‹è¯•å’Œä¼˜åŒ–å·¥å…·æ¼”ç¤º")
    print("ğŸŒŸ" * 30)
    
    # åŸºç¡€æ¼”ç¤º
    demo_latency_measurement()
    demo_throughput_measurement()
    demo_resource_monitoring()
    demo_performance_report()
    
    # ä¼˜åŒ–æ¼”ç¤º
    demo_optimizer_connection_pool()
    demo_optimizer_lru_cache()
    demo_optimizer_thread_pool()
    demo_optimizer_memory_pool()
    demo_concurrency_limiter()
    demo_batch_processor()
    
    # ç»¼åˆæ¼”ç¤º
    demo_comparison_before_after()
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    main()

"""
Claude Integration Example

å±•ç¤º Claude API çš„æ·±åº¦é›†æˆã€‚
"""

import asyncio
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from agent_os_kernel import AgentOSKernel
from agent_os_kernel.llm import LLMProviderFactory, LLMConfig


async def demo_claude():
    """Claude é›†æˆç¤ºä¾‹"""
    print("=" * 60)
    print("Claude é›†æˆç¤ºä¾‹")
    print("=" * 60)
    
    # æ£€æŸ¥ API Key
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        print("âš ï¸  è¯·è®¾ç½® ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    print(f"\nâœ… API Key å·²é…ç½®")
    
    # åˆ›å»º Provider
    factory = LLMProviderFactory()
    
    config = LLMConfig(
        provider="anthropic",
        model="claude-sonnet-4-20250514",
        api_key=api_key,
        max_tokens=8192,
        temperature=0.7
    )
    
    print(f"\nğŸ“¦ åˆ›å»º Claude Provider...")
    provider = factory.create(config)
    
    # åˆå§‹åŒ–
    print(f"\nğŸš€ åˆå§‹åŒ– Provider...")
    await provider.initialize()
    
    # æµ‹è¯•è°ƒç”¨
    messages = [
        {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
    ]
    
    print(f"\nğŸ’¬ å‘é€æµ‹è¯•è¯·æ±‚...")
    response = await provider.complete(messages)
    
    print(f"\nğŸ“ Claude å›å¤:")
    print("-" * 40)
    print(response.content[:500])
    print("-" * 40)
    
    # å…³é—­
    await provider.shutdown()
    
    print(f"\nâœ… Claude é›†æˆæµ‹è¯•å®Œæˆ!")
    
    return provider


async def demo_claude_tools():
    """Claude å·¥å…·è°ƒç”¨ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("Claude å·¥å…·è°ƒç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        print("âš ï¸  ANTHROPIC_API_KEY æœªè®¾ç½®")
        return
    
    factory = LLMProviderFactory()
    
    config = LLMConfig(
        provider="anthropic",
        model="claude-sonnet-4-20250514",
        api_key=api_key,
        max_tokens=8192
    )
    
    provider = factory.create(config)
    await provider.initialize()
    
    # å®šä¹‰å·¥å…·
    tools = [
        {
            "name": "calculator",
            "description": "è®¡ç®—æ•°å­¦è¡¨è¾¾å¼",
            "input_schema": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "è¦è®¡ç®—çš„æ•°å­¦è¡¨è¾¾å¼"
                    }
                },
                "required": ["expression"]
            }
        },
        {
            "name": "search",
            "description": "æœç´¢ä¿¡æ¯",
            "input_schema": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢æŸ¥è¯¢"
                    }
                },
                "required": ["query"]
            }
        }
    ]
    
    messages = [
        {"role": "user", "content": "è®¡ç®— 123 * 456ï¼Œç„¶åæœç´¢ AI çš„æœ€æ–°å‘å±•"}
    ]
    
    print(f"\nğŸ”§ å‘é€å·¥å…·è°ƒç”¨è¯·æ±‚...")
    response = await provider.complete(messages, tools=tools)
    
    print(f"\nğŸ“ å“åº”:")
    print(response.content)
    
    if response.tool_calls:
        print(f"\nğŸ”§ å·¥å…·è°ƒç”¨:")
        for tool_call in response.tool_calls:
            print(f"   - {tool_call}")
    
    await provider.shutdown()


async def demo_claude_streaming():
    """Claude æµå¼è¾“å‡ºç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("Claude æµå¼è¾“å‡ºç¤ºä¾‹")
    print("=" * 60)
    
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        print("âš ï¸  ANTHROPIC_API_KEY æœªè®¾ç½®")
        return
    
    factory = LLMProviderFactory()
    
    config = LLMConfig(
        provider="anthropic",
        model="claude-sonnet-4-20250514",
        api_key=api_key
    )
    
    provider = factory.create(config)
    await provider.initialize()
    
    messages = [
        {"role": "user", "content": "å†™ä¸€é¦–å…³äº AI çš„çŸ­è¯—"}
    ]
    
    print(f"\nğŸŒŠ æµå¼è¾“å‡º:")
    print("-" * 40)
    
    stream = await provider.stream_complete(messages)
    
    async for chunk in stream.chunks:
        print(chunk, end="", flush=True)
    
    print("\n" + "-" * 40)
    
    await provider.shutdown()


async def demo_claude_context():
    """Claude ä¸Šä¸‹æ–‡ç®¡ç†ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("Claude ä¸Šä¸‹æ–‡ç®¡ç†ç¤ºä¾‹")
    print("=" * 60)
    
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        print("âš ï¸  ANTHROPIC_API_KEY æœªè®¾ç½®")
        return
    
    factory = LLMProviderFactory()
    
    config = LLMConfig(
        provider="anthropic",
        model="claude-sonnet-4-20250514",
        api_key=api_key,
        max_tokens=4096
    )
    
    provider = factory.create(config)
    await provider.initialize()
    
    # æ¨¡æ‹Ÿé•¿å¯¹è¯
    conversation = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"},
    ]
    
    # æ·»åŠ  50 æ¡æ¶ˆæ¯
    for i in range(50):
        conversation.append({
            "role": "user",
            "content": f"ç”¨æˆ·æ¶ˆæ¯ {i+1}: è¿™æ˜¯ç¬¬ {i+1} æ¡æ¶ˆæ¯ã€‚"
        })
        conversation.append({
            "role": "assistant",
            "content": f"åŠ©æ‰‹å›å¤ {i+1}: æ”¶åˆ°ï¼Œè¿™æ˜¯ç¬¬ {i+1} æ¡å›å¤ã€‚"
        })
    
    conversation.append({
        "role": "user",
        "content": "æ€»ç»“æˆ‘ä»¬çš„å¯¹è¯"
    })
    
    # ç»Ÿè®¡ Token
    from agent_os_kernel.llm import Message
    
    msgs = [Message(**m) for m in conversation if m["role"] != "system"]
    token_count = await provider.count_tokens("\n".join([m.content for m in msgs]))
    
    print(f"\nğŸ“Š å¯¹è¯ç»Ÿè®¡:")
    print(f"   æ¶ˆæ¯æ•°: {len(conversation)}")
    print(f"   ä¼°ç®— Token: {token_count}")
    print(f"   æœ€å¤§é™åˆ¶: {config.max_tokens}")
    
    # å¦‚æœè¶…è¿‡é™åˆ¶ï¼Œä½¿ç”¨å‹ç¼©
    if token_count > config.max_tokens:
        print(f"\nğŸ”§ ä¸Šä¸‹æ–‡è¶…è¿‡é™åˆ¶ï¼Œä½¿ç”¨å‹ç¼©...")
        # è¿™é‡Œå¯ä»¥é›†æˆ Context Compressor
        print(f"   (è¯·å‚è€ƒ optimization_demo.py ä¸­çš„å‹ç¼©ç¤ºä¾‹)")
    
    await provider.shutdown()


async def demo_with_kernel():
    """åœ¨ Agent ä¸­ä½¿ç”¨ Claude"""
    print("\n" + "=" * 60)
    print("åœ¨ Agent ä¸­ä½¿ç”¨ Claude")
    print("=" * 60)
    
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        print("âš ï¸  ANTHROPIC_API_KEY æœªè®¾ç½®")
        return
    
    # åˆ›å»ºå†…æ ¸
    kernel = AgentOSKernel()
    
    # é…ç½® Claude Provider
    print(f"\nâš™ï¸  é…ç½® Agent...")
    
    agent_pid = kernel.spawn_agent(
        name="ClaudeAssistant",
        task="ä½ æ˜¯ä¸€ä¸ªä½¿ç”¨ Claude çš„ä¸“ä¸šåŠ©æ‰‹",
        priority=50
    )
    
    print(f"âœ… Agent åˆ›å»º: {agent_pid[:16]}...")
    
    # è·å– Agent çŠ¶æ€
    status = kernel.scheduler.get_process_status(agent_pid)
    print(f"\nğŸ“Š Agent çŠ¶æ€:")
    print(f"   åç§°: {status.get('name', 'N/A')}")
    print(f"   çŠ¶æ€: {status.get('state', 'N/A')}")
    
    # æ¸…ç†
    kernel.scheduler.terminate_process(agent_pid, reason="demo complete")
    
    return kernel


async def main():
    """ä¸»å‡½æ•°"""
    print("\nğŸš€ Claude é›†æˆç¤ºä¾‹")
    print("=" * 60)
    
    # 1. åŸºç¡€é›†æˆ
    await demo_claude()
    
    # 2. å·¥å…·è°ƒç”¨
    await demo_claude_tools()
    
    # 3. æµå¼è¾“å‡º
    await demo_claude_streaming()
    
    # 4. ä¸Šä¸‹æ–‡ç®¡ç†
    await demo_claude_context()
    
    # 5. åœ¨ Agent ä¸­ä½¿ç”¨
    await demo_with_kernel()
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰ç¤ºä¾‹å®Œæˆ!")
    print("=" * 60)
    
    print("\nğŸ“š è¿›ä¸€æ­¥é˜…è¯»:")
    print("   - Anthropic Docs: https://docs.anthropic.com/")
    print("   - Claude API: https://docs.anthropic.com/claude-reference/")


if __name__ == "__main__":
    asyncio.run(main())

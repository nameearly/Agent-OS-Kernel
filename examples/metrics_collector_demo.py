# -*- coding: utf-8 -*-
"""
Metrics Collector Demo - Agent-OS-Kernel æŒ‡æ ‡æ”¶é›†å™¨æ¼”ç¤º

æ¼”ç¤ºæŒ‡æ ‡æ”¶é›†å™¨çš„ä½¿ç”¨æ–¹æ³•,åŒ…æ‹¬:
- è®¡æ•°å™¨ (Counter) çš„åˆ›å»ºå’Œä½¿ç”¨
- ä»ªè¡¨ç›˜ (Gauge) çš„åˆ›å»ºå’Œä½¿ç”¨
- ç›´æ–¹å›¾ (Histogram) çš„åˆ›å»ºå’Œä½¿ç”¨
- æŒ‡æ ‡å¯¼å‡ºåŠŸèƒ½
"""

import time
import random
import threading
from agent_os_kernel.core.metrics_collector import (
    MetricsRegistry,
    Counter,
    Gauge,
    Histogram,
    ExportFormat,
    create_metrics_registry,
    create_counter,
    create_gauge,
    create_histogram,
    counter,
    gauge,
    histogram,
    export_metrics,
)


def demo_counter():
    """æ¼”ç¤ºè®¡æ•°å™¨åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("ğŸ“Š è®¡æ•°å™¨ (Counter) æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºè®¡æ•°å™¨
    request_counter = create_counter(
        "http_requests_total",
        "HTTPè¯·æ±‚æ€»æ•°",
        labels=["method", "status"]
    )
    
    # æ¨¡æ‹Ÿä¸€äº›è¯·æ±‚
    methods = ["GET", "POST", "PUT", "DELETE"]
    statuses = ["200", "201", "400", "404", "500"]
    
    print("\næ¨¡æ‹ŸHTTPè¯·æ±‚:")
    for i in range(20):
        method = random.choice(methods)
        status = random.choice(statuses)
        request_counter.inc(label_values={"method": method, "status": status})
        print(f"  è¯·æ±‚ {i+1}: {method} -> {status}")
    
    # æ˜¾ç¤ºè®¡æ•°å™¨å€¼
    print("\nè®¡æ•°å™¨ç»Ÿè®¡:")
    print(f"  æ€»è¯·æ±‚æ•°: {request_counter.value()}")
    
    # æ˜¾ç¤ºæŒ‰çŠ¶æ€åˆ†ç»„
    print("\n  æŒ‰çŠ¶æ€åˆ†ç»„:")
    for status in statuses:
        value = request_counter.value({"status": status})
        if value > 0:
            print(f"    {status}: {int(value)}")
    
    # æ˜¾ç¤ºæŒ‰æ–¹æ³•åˆ†ç»„
    print("\n  æŒ‰æ–¹æ³•åˆ†ç»„:")
    for method in methods:
        value = request_counter.value({"method": method})
        if value > 0:
            print(f"    {method}: {int(value)}")


def demo_gauge():
    """æ¼”ç¤ºä»ªè¡¨ç›˜åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("ğŸ“ˆ ä»ªè¡¨ç›˜ (Gauge) æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºä»ªè¡¨ç›˜
    memory_gauge = create_gauge(
        "memory_usage_bytes",
        "å†…å­˜ä½¿ç”¨é‡ (å­—èŠ‚)",
        labels=["server"]
    )
    
    cpu_gauge = create_gauge(
        "cpu_usage_percent",
        "CPUä½¿ç”¨ç‡ (%)"
    )
    
    # æ¨¡æ‹ŸæœåŠ¡å™¨ç›‘æ§
    servers = ["server-1", "server-2", "server-3"]
    
    print("\næ¨¡æ‹ŸæœåŠ¡å™¨ç›‘æ§æ•°æ®:")
    for server in servers:
        memory = random.randint(512, 2048) * 1024 * 1024  # 512MB - 2GB
        memory_gauge.set(memory, label_values={"server": server})
        print(f"  {server}: å†…å­˜ = {memory / (1024*1024):.0f} MB")
    
    # æ¨¡æ‹ŸCPUä½¿ç”¨ç‡å˜åŒ–
    print("\nCPUä½¿ç”¨ç‡å˜åŒ–:")
    for i in range(5):
        cpu = random.randint(10, 90)
        cpu_gauge.set(cpu)
        print(f"  æ—¶åˆ» {i+1}: CPU = {cpu}%")
        time.sleep(0.5)
    
    print(f"\næœ€ç»ˆCPUä½¿ç”¨ç‡: {cpu_gauge.value()}%")


def demo_histogram():
    """æ¼”ç¤ºç›´æ–¹å›¾åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("ğŸ“‰ ç›´æ–¹å›¾ (Histogram) æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºç›´æ–¹å›¾
    latency_histogram = create_histogram(
        "request_latency_seconds",
        "è¯·æ±‚å»¶è¿Ÿ (ç§’)",
        labels=["endpoint"],
        buckets=(0.1, 0.5, 1.0, 2.0, 5.0, float('inf'))
    )
    
    endpoints = ["/api/users", "/api/orders", "/api/products"]
    
    print("\næ¨¡æ‹Ÿè¯·æ±‚å»¶è¿Ÿæ•°æ®:")
    for endpoint in endpoints:
        print(f"\n  ç«¯ç‚¹: {endpoint}")
        for i in range(50):
            # ç”Ÿæˆç¬¦åˆæ­£æ€åˆ†å¸ƒçš„å»¶è¿Ÿ
            latency = max(0.01, random.gauss(0.5, 0.3))
            latency_histogram.observe(latency, label_values={"endpoint": endpoint})
        
        count = latency_histogram.get_count({"endpoint": endpoint})
        total = latency_histogram.get_sum({"endpoint": endpoint})
        avg = total / count if count > 0 else 0
        
        print(f"    è¯·æ±‚æ•°: {count}")
        print(f"    æ€»å»¶è¿Ÿ: {total:.2f}s")
        print(f"    å¹³å‡å»¶è¿Ÿ: {avg:.3f}s")
    
    # æ˜¾ç¤ºç™¾åˆ†ä½æ•°
    print("\nè¯·æ±‚å»¶è¿Ÿç™¾åˆ†ä½æ•°:")
    for endpoint in endpoints:
        percentiles = latency_histogram.get_percentiles(
            [0.5, 0.9, 0.95, 0.99],
            label_values={"endpoint": endpoint}
        )
        print(f"\n  {endpoint}:")
        print(f"    P50: {percentiles.get(0.5, 0):.3f}s")
        print(f"    P90: {percentiles.get(0.9, 0):.3f}s")
        print(f"    P95: {percentiles.get(0.95, 0):.3f}s")
        print(f"    P99: {percentiles.get(0.99, 0):.3f}s")
    
    # æ˜¾ç¤ºbucketåˆ†å¸ƒ
    print("\nå»¶è¿Ÿåˆ†å¸ƒ (Bucket):")
    bucket_counts = latency_histogram.get_bucket_counts({"endpoint": "/api/users"})
    bucket_labels = ["0.1s", "0.5s", "1.0s", "2.0s", "5.0s", "+Inf"]
    buckets = (0.1, 0.5, 1.0, 2.0, 5.0, float('inf'))
    print("  Bucketåˆ†å¸ƒ (/api/users):")
    for label, bucket in zip(bucket_labels, buckets):
        count = bucket_counts.get(bucket, 0)
        print(f"    <= {label}: {count}")


def demo_metrics_export():
    """æ¼”ç¤ºæŒ‡æ ‡å¯¼å‡ºåŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("ğŸ“¤ æŒ‡æ ‡å¯¼å‡ºæ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºæ¼”ç¤ºç”¨æ³¨å†Œè¡¨
    demo_registry = create_metrics_registry("demo")
    
    # æ·»åŠ ä¸€äº›æŒ‡æ ‡
    demo_registry.create_counter("http_requests", "HTTPè¯·æ±‚æ•°", ["method"])
    demo_registry.create_gauge("active_connections", "æ´»è·ƒè¿æ¥æ•°")
    demo_registry.create_histogram("request_duration", "è¯·æ±‚æŒç»­æ—¶é—´", ["endpoint"])
    
    # å¡«å……æ•°æ®
    c = demo_registry.get_counter("http_requests")
    c.inc(label_values={"method": "GET"})
    c.inc(5, label_values={"method": "POST"})
    
    g = demo_registry.get_gauge("active_connections")
    g.set(150)
    
    h = demo_registry.get_histogram("request_duration")
    h.observe(0.1, label_values={"endpoint": "/home"})
    h.observe(0.3, label_values={"endpoint": "/home"})
    h.observe(0.5, label_values={"endpoint": "/api"})
    
    # å¯¼å‡ºä¸ºJSON
    print("\n1. JSON æ ¼å¼å¯¼å‡º:")
    print("-" * 40)
    json_output = demo_registry.export(ExportFormat.JSON)
    print(json_output[:500] + "..." if len(json_output) > 500 else json_output)
    
    # å¯¼å‡ºä¸ºPrometheus
    print("\n2. Prometheus æ ¼å¼å¯¼å‡º:")
    print("-" * 40)
    prom_output = demo_registry.export(ExportFormat.PROMETHEUS)
    print(prom_output)
    
    # å¯¼å‡ºä¸ºæ–‡æœ¬
    print("\n3. æ–‡æœ¬æ ¼å¼å¯¼å‡º:")
    print("-" * 40)
    text_output = demo_registry.export(ExportFormat.TEXT)
    print(text_output)


def demo_thread_safety():
    """æ¼”ç¤ºçº¿ç¨‹å®‰å…¨"""
    print("\n" + "=" * 60)
    print("ğŸ§µ çº¿ç¨‹å®‰å…¨æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºå…±äº«è®¡æ•°å™¨
    global_counter = Counter("global_counter", "å…¨å±€è®¡æ•°å™¨")
    
    def worker(thread_id: int):
        """å·¥ä½œçº¿ç¨‹"""
        for _ in range(100):
            global_counter.inc()
            time.sleep(0.001)
    
    print("\nå¯åŠ¨10ä¸ªçº¿ç¨‹,æ¯ä¸ªçº¿ç¨‹å¢åŠ 100æ¬¡:")
    threads = [threading.Thread(target=worker, args=(i,)) for i in range(10)]
    
    start_time = time.time()
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    elapsed = time.time() - start_time
    
    print(f"  æœŸæœ›å€¼: 1000")
    print(f"  å®é™…å€¼: {int(global_counter.value())}")
    print(f"  è€—æ—¶: {elapsed:.3f}s")
    print(f"  çº¿ç¨‹å®‰å…¨: {'âœ“' if global_counter.value() == 1000 else 'âœ—'}")


def demo_real_world_scenario():
    """æ¼”ç¤ºçœŸå®åœºæ™¯ - WebæœåŠ¡ç›‘æ§"""
    print("\n" + "=" * 60)
    print("ğŸŒ çœŸå®åœºæ™¯: WebæœåŠ¡ç›‘æ§")
    print("=" * 60)
    
    # åˆ›å»ºæœåŠ¡ç›‘æ§æ³¨å†Œè¡¨
    service_registry = create_metrics_registry("web_service")
    
    # å®šä¹‰æŒ‡æ ‡
    requests_total = service_registry.create_counter(
        "http_server_requests_total",
        "HTTPæœåŠ¡å™¨è¯·æ±‚æ€»æ•°",
        ["method", "endpoint", "status"]
    )
    
    request_duration = service_registry.create_histogram(
        "http_server_request_duration_seconds",
        "HTTPè¯·æ±‚æŒç»­æ—¶é—´",
        ["method", "endpoint"],
        buckets=(0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, float('inf'))
    )
    
    active_connections = service_registry.create_gauge(
        "http_server_active_connections",
        "æ´»è·ƒè¿æ¥æ•°"
    )
    
    in_flight_requests = service_registry.create_gauge(
        "http_server_requests_in_flight",
        "å¤„ç†ä¸­çš„è¯·æ±‚æ•°"
    )
    
    print("\næ¨¡æ‹ŸWebæœåŠ¡è¯·æ±‚æµ:")
    
    endpoints = ["/", "/api/users", "/api/products", "/api/orders"]
    methods = ["GET", "POST", "PUT", "DELETE"]
    
    for i in range(30):
        # æ¨¡æ‹Ÿæ–°è¯·æ±‚
        endpoint = random.choice(endpoints)
        method = random.choice(methods)
        in_flight_requests.inc()
        active_connections.inc()
        
        # æ¨¡æ‹Ÿè¯·æ±‚å¤„ç†å»¶è¿Ÿ
        latency = random.gauss(0.2, 0.1)
        time.sleep(0.05)
        
        # è¯·æ±‚å®Œæˆ
        status = random.choice(["200", "201", "400", "404", "500"], 
                              weights=[60, 15, 15, 8, 2])
        in_flight_requests.dec()
        
        # è®°å½•æŒ‡æ ‡
        requests_total.inc(label_values={
            "method": method,
            "endpoint": endpoint,
            "status": status
        })
        request_duration.observe(latency, label_values={
            "method": method,
            "endpoint": endpoint
        })
        
        if (i + 1) % 10 == 0:
            print(f"  å·²å¤„ç† {i + 1} ä¸ªè¯·æ±‚...")
    
    # æ˜¾ç¤ºç›‘æ§ç»“æœ
    print("\nç›‘æ§ç»Ÿè®¡:")
    print(f"  æ´»è·ƒè¿æ¥: {int(active_connections.value())}")
    print(f"  å¤„ç†ä¸­è¯·æ±‚: {int(in_flight_requests.value())}")
    
    print("\nè¯·æ±‚ç»Ÿè®¡:")
    requests = requests_total.get_all_values()
    for (method, endpoint, status), count in requests.items():
        print(f"    {method} {endpoint} -> {status}: {int(count)}")
    
    print("\nå»¶è¿Ÿç»Ÿè®¡:")
    for endpoint in endpoints:
        count = request_duration.get_count({"endpoint": endpoint})
        if count > 0:
            total = request_duration.get_sum({"endpoint": endpoint})
            percentiles = request_duration.get_percentiles(
                [0.5, 0.9, 0.95],
                label_values={"endpoint": endpoint}
            )
            print(f"  {endpoint}:")
            print(f"    è¯·æ±‚æ•°: {count}")
            print(f"    å¹³å‡: {total/count:.3f}s")
            print(f"    P50: {percentiles.get(0.5, 0):.3f}s")
            print(f"    P90: {percentiles.get(0.9, 0):.3f}s")
            print(f"    P95: {percentiles.get(0.95, 0):.3f}s")
    
    # å¯¼å‡ºPrometheusæ ¼å¼
    print("\nPrometheusæŒ‡æ ‡æ ¼å¼:")
    print("-" * 40)
    print(service_registry.export(ExportFormat.PROMETHEUS))


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ æŒ‡æ ‡æ”¶é›†å™¨ (Metrics Collector) æ¼”ç¤º")
    print("=" * 60)
    
    # è¿è¡Œå„ä¸ªæ¼”ç¤º
    demo_counter()
    input("\næŒ‰å›è½¦é”®ç»§ç»­...")
    
    demo_gauge()
    input("\næŒ‰å›è½¦é”®ç»§ç»­...")
    
    demo_histogram()
    input("\næŒ‰å›è½¦é”®ç»§ç»­...")
    
    demo_metrics_export()
    input("\næŒ‰å›è½¦é”®ç»§ç»­...")
    
    demo_thread_safety()
    input("\næŒ‰å›è½¦é”®ç»§ç»­...")
    
    demo_real_world_scenario()
    
    print("\n" + "=" * 60)
    print("âœ… æ¼”ç¤ºå®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    main()

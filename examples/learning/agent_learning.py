"""
Agent è‡ªå­¦ä¹ ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨è½¨è¿¹è®°å½•å’Œç­–ç•¥ä¼˜åŒ–ï¼š
1. è½¨è¿¹è®°å½•
2. ç­–ç•¥åˆ†æ
3. è‡ªåŠ¨ä¼˜åŒ–
"""

import asyncio
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from agent_os_kernel import AgentOSKernel
from agent_os_kernel.core.learning import TrajectoryRecorder, AgentOptimizer
from agent_os_kernel.core.learning.trajectory import TrajectoryPhase


async def demo_trajectory_recording():
    """è½¨è¿¹è®°å½•ç¤ºä¾‹"""
    print("=" * 60)
    print("è½¨è¿¹è®°å½•ç¤ºä¾‹")
    print("=" * 60)
    
    # åˆ›å»ºè®°å½•å™¨
    recorder = TrajectoryRecorder(storage_dir="./demo_trajectories")
    
    # æ¨¡æ‹Ÿ Agent æ‰§è¡Œ
    kernel = AgentOSKernel()
    
    # åˆ›å»º Agent
    pid = kernel.spawn_agent(name="LearningAgent", task="å­¦ä¹ å¦‚ä½•è§£å†³é—®é¢˜", priority=50)
    agent_name = "LearningAgent"
    
    print(f"\nğŸ¤– Agent: {agent_name} ({pid[:16]}...)")
    
    # å¼€å§‹è®°å½•
    traj_id = recorder.start_recording(agent_name, pid, "å­¦ä¹ å¦‚ä½•è§£å†³é—®é¢˜")
    print(f"ğŸ“ å¼€å§‹è®°å½•è½¨è¿¹: {traj_id}")
    
    # æ¨¡æ‹Ÿæ‰§è¡Œæ­¥éª¤
    print("\nğŸ“Š è®°å½•æ‰§è¡Œæ­¥éª¤:")
    
    # æ€è€ƒé˜¶æ®µ
    recorder.add_step(
        phase=TrajectoryPhase.THINKING,
        thought="åˆ†æé—®é¢˜çš„æ ¸å¿ƒè¦ç´ ",
        confidence=0.8
    )
    print("  ğŸ§  æ€è€ƒ: åˆ†æé—®é¢˜çš„æ ¸å¿ƒè¦ç´ ")
    
    # è§„åˆ’é˜¶æ®µ
    recorder.add_step(
        phase=TrajectoryPhase.PLANNING,
        action={"plan": "åˆ†ä¸‰æ­¥è§£å†³"},
        confidence=0.7
    )
    print("  ğŸ“‹ è§„åˆ’: åˆ†ä¸‰æ­¥è§£å†³")
    
    # æ‰§è¡Œé˜¶æ®µ
    recorder.add_step(
        phase=TrajectoryPhase.EXECUTING,
        tool_call={"name": "calculator", "params": {"expression": "100/5"}},
        observation="è®¡ç®—å®Œæˆ: 20",
        confidence=0.9
    )
    print("  âš¡ æ‰§è¡Œ: calculator(100/5) = 20")
    
    # åæ€é˜¶æ®µ
    recorder.add_step(
        phase=TrajectoryPhase.REFLECTING,
        reflection="ç¬¬ä¸€æ­¥æˆåŠŸï¼Œç»§ç»­ä¸‹ä¸€æ­¥",
        confidence=0.85
    )
    print("  ğŸ¤” åæ€: ç¬¬ä¸€æ­¥æˆåŠŸï¼Œç»§ç»­ä¸‹ä¸€æ­¥")
    
    # å®Œæˆè®°å½•
    trajectory = recorder.finish_recording(
        outcome="ä»»åŠ¡å®Œæˆ",
        success=True,
        total_tokens=500,
        total_tools_used=3
    )
    
    print(f"\nâœ… è½¨è¿¹è®°å½•å®Œæˆ:")
    print(f"   ID: {trajectory.trajectory_id}")
    print(f"   æ­¥éª¤æ•°: {len(trajectory.steps)}")
    print(f"   æˆåŠŸç‡: {trajectory.success}")
    print(f"   æŒç»­æ—¶é—´: {trajectory.duration():.2f}s")
    
    return recorder


async def demo_trajectory_analysis(recorder: TrajectoryRecorder):
    """è½¨è¿¹åˆ†æç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("è½¨è¿¹åˆ†æç¤ºä¾‹")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿå¤šä¸ªè½¨è¿¹
    print("\nğŸ“ˆ æ¨¡æ‹Ÿæ›´å¤šè½¨è¿¹æ•°æ®...")
    
    for i in range(5):
        traj_id = recorder.start_recording(
            agent_name="LearningAgent",
            agent_pid=f"pid_{i}",
            task=f"ä»»åŠ¡ {i+1}"
        )
        
        # éšæœºæˆåŠŸ/å¤±è´¥
        success = i < 4  # 80% æˆåŠŸç‡
        
        steps = 3 + i % 3
        for j in range(steps):
            recorder.add_step(
                phase=TrajectoryPhase.EXECUTING,
                action={"step": j},
                confidence=0.6 + (0.1 * j) if success else 0.4
            )
        
        recorder.finish_recording(
            outcome="æˆåŠŸ" if success else "å¤±è´¥",
            success=success,
            total_tokens=300 + i * 50,
            total_tools_used=2 + j
        )
    
    print("âœ… ç”Ÿæˆäº† 5 æ¡è½¨è¿¹æ•°æ®")
    
    # åˆ†æç­–ç•¥
    print("\nğŸ” å¼€å§‹ç­–ç•¥åˆ†æ...")
    optimizer = AgentOptimizer(recorder)
    analysis = optimizer.analyze("LearningAgent")
    
    print(f"\nğŸ“Š åˆ†æç»“æœ:")
    print(f"   æˆåŠŸç‡: {analysis.success_rate:.1%}")
    print(f"   å¹³å‡ Token: {analysis.avg_tokens:.0f}")
    print(f"   å¹³å‡è€—æ—¶: {analysis.avg_duration:.1f}s")
    
    if analysis.strengths:
        print(f"\nğŸ’ª ä¼˜åŠ¿:")
        for strength in analysis.strengths:
            print(f"   âœ… {strength}")
    
    if analysis.weaknesses:
        print(f"\nâš ï¸ åŠ£åŠ¿:")
        for weakness in analysis.weaknesses:
            print(f"   âŒ {weakness}")
    
    if analysis.suggestions:
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for suggestion in analysis.suggestions[:3]:
            print(f"   [{suggestion.priority}] {suggestion.description}")
    
    return optimizer


async def demo_optimization(optimizer: AgentOptimizer):
    """ä¼˜åŒ–ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("è‡ªåŠ¨ä¼˜åŒ–ç¤ºä¾‹")
    print("=" * 60)
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\nğŸ“‹ ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š...")
    report = optimizer.get_report("LearningAgent")
    
    print(f"\nğŸ“Š æŠ¥å‘Šæ‘˜è¦:")
    summary = report['summary']
    for key, value in summary.items():
        print(f"   {key}: {value}")
    
    # ç”Ÿæˆä¼˜åŒ–åçš„ Prompt
    print("\nğŸ“ ç”Ÿæˆçš„ Prompt æ¨¡æ¿:")
    template = optimizer.generate_prompt_template("LearningAgent")
    print("-" * 40)
    print(template)
    print("-" * 40)
    
    # åº”ç”¨ä¼˜åŒ–
    print("\nğŸš€ åº”ç”¨ä¼˜åŒ–...")
    result = optimizer.batch_optimize("LearningAgent")
    print(f"   åº”ç”¨äº† {result['applied']} ä¸ªä¼˜åŒ–å»ºè®®")
    
    return optimizer


async def demo_metrics():
    """æŒ‡æ ‡ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("æŒ‡æ ‡ç›‘æ§ç¤ºä¾‹")
    print("=" * 60)
    
    recorder = TrajectoryRecorder()
    
    # åˆ›å»ºä¸€äº›è½¨è¿¹
    for i in range(10):
        traj_id = recorder.start_recording(
            agent_name="MetricsAgent",
            agent_pid=f"metrics_{i}",
            task=f"æµ‹è¯•ä»»åŠ¡ {i}"
        )
        
        for j in range(3):
            recorder.add_step(
                phase=TrajectoryPhase.EXECUTING,
                action={"step": j}
            )
        
        recorder.finish_recording(
            outcome="æˆåŠŸ" if i % 2 == 0 else "å¤±è´¥",
            success=i % 2 == 0,
            total_tokens=200 + i * 30,
            total_tools_used=2
        )
    
    # è·å–æŒ‡æ ‡
    metrics = recorder.get_average_metrics("MetricsAgent")
    print("\nğŸ“ˆ æŒ‡æ ‡:")
    for key, value in metrics.items():
        print(f"   {key}: {value}")
    
    # è·å–æˆåŠŸç‡
    rate = recorder.get_success_rate("MetricsAgent")
    print(f"\nğŸ¯ æˆåŠŸç‡: {rate:.1%}")
    
    # è·å–å¸¸è§æ¨¡å¼
    patterns = recorder.get_common_patterns("MetricsAgent")
    print(f"\nğŸ”„ å¸¸è§æ¨¡å¼ (Top 3):")
    for pattern, count in list(patterns.items())[:3]:
        print(f"   {pattern}: {count}æ¬¡")
    
    return recorder


async def main():
    """ä¸»å‡½æ•°"""
    print("\nğŸš€ Agent è‡ªå­¦ä¹ ç³»ç»Ÿç¤ºä¾‹")
    print("=" * 60)
    
    # 1. è½¨è¿¹è®°å½•
    recorder = await demo_trajectory_recording()
    
    # 2. è½¨è¿¹åˆ†æ
    optimizer = await demo_trajectory_analysis(recorder)
    
    # 3. è‡ªåŠ¨ä¼˜åŒ–
    await demo_optimization(optimizer)
    
    # 4. æŒ‡æ ‡ç›‘æ§
    await demo_metrics()
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰ç¤ºä¾‹å®Œæˆ!")
    print("=" * 60)
    
    print("\nğŸ“š è¿›ä¸€æ­¥é˜…è¯»:")
    print("   - è½¨è¿¹å­¦ä¹ : AIWaves Agents è®ºæ–‡")
    print("   - ç­–ç•¥ä¼˜åŒ–: Reinforcement Learning")
    print("   - ç»éªŒç§¯ç´¯: Experience Replay")


if __name__ == "__main__":
    asyncio.run(main())

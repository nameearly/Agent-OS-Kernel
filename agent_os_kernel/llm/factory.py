# -*- coding: utf-8 -*-
"""LLM Provider Factory - Provider ç®¡ç†å·¥å‚

å‚è€ƒ AIOS è®¾è®¡ï¼Œæä¾›ç»Ÿä¸€çš„ Provider åˆ›å»ºæ¥å£ã€‚
"""

import os
import logging
from typing import Dict, Optional, List, Any
from dataclasses import dataclass
from .provider import (
    LLMProvider, LLMConfig, Message,
    ProviderType, register_provider, get_provider
)

logger = logging.getLogger(__name__)


@dataclass
class ProviderInfo:
    """Provider ä¿¡æ¯"""
    type: ProviderType
    name: str
    description: str
    requires_api_key: bool = True
    local: bool = False
    default_model: str = ""


class LLMProviderFactory:
    """LLM Provider å·¥å‚"""
    
    # Provider æ³¨å†Œè¡¨
    PROVIDERS: Dict[str, ProviderInfo] = {
        "openai": ProviderInfo(
            type=ProviderType("openai"),
            name="OpenAI",
            description="GPT-4, GPT-4 Turbo, GPT-3.5 Turbo",
            requires_api_key=True,
            default_model="gpt-4o"
        ),
        "anthropic": ProviderInfo(
            type=ProviderType("anthropic"),
            name="Anthropic",
            description="Claude 3.5, Claude 3, Claude 2",
            requires_api_key=True,
            default_model="claude-sonnet-4-20250514"
        ),
        "deepseek": ProviderInfo(
            type=ProviderType("deepseek"),
            name="DeepSeek",
            description="DeepSeek Chat, DeepSeek Reasoner",
            requires_api_key=True,
            default_model="deepseek-chat"
        ),
        "groq": ProviderInfo(
            type=ProviderType("groq"),
            name="Groq",
            description="é«˜é€Ÿæ¨ç† (Llama, Gemma, Mixtral)",
            requires_api_key=True,
            default_model="llama-3.3-70b-versatile"
        ),
        "ollama": ProviderInfo(
            type=ProviderType("ollama"),
            name="Ollama",
            description="æœ¬åœ° LLM è¿è¡Œ (Qwen, Llama, Mistral)",
            requires_api_key=False,
            local=True,
            default_model="qwen2.5:7b"
        ),
        "vllm": ProviderInfo(
            type=ProviderType("vllm"),
            name="vLLM",
            description="é«˜æ€§èƒ½æ¨ç†å¼•æ“",
            requires_api_key=False,
            local=True,
            default_model="meta-llama/Llama-3.1-8B-Instruct"
        ),
        # ğŸ‡¨ğŸ‡³ ä¸­å›½æ¨¡å‹
        "kimi": ProviderInfo(
            type=ProviderType("kimi"),
            name="Kimi (Moonshot AI)",
            description="Kimi é•¿æ–‡æœ¬æ¨¡å‹ï¼Œæ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡",
            requires_api_key=True,
            default_model="moonshot-v1-8k"
        ),
        "minimax": ProviderInfo(
            type=ProviderType("minimax"),
            name="MiniMax",
            description="MiniMax èŠå¤©æ¨¡å‹",
            requires_api_key=True,
            default_model="abab6.5s-chat"
        ),
        "qwen": ProviderInfo(
            type=ProviderType("qwen"),
            name="Qwen (Alibaba)",
            description="é€šä¹‰åƒé—® Qwen-Max, Qwen-Plus",
            requires_api_key=True,
            default_model="qwen-turbo"
        ),
    }
    
    def __init__(self):
        self._active_providers: Dict[str, LLMProvider] = {}
        self._default_provider: Optional[str] = None
    
    def create(self, config: LLMConfig) -> LLMProvider:
        """åˆ›å»º Provider å®ä¾‹"""
        provider_class = get_provider(config.provider)
        
        if not provider_class:
            raise ValueError(f"Unknown provider type: {config.provider}")
        
        provider = provider_class(config)
        logger.info(f"Created provider: {config.provider.value} ({config.model})")
        
        return provider
    
    def create_from_dict(self, config_data: Dict) -> LLMProvider:
        """ä»å­—å…¸åˆ›å»º Provider"""
        config = LLMConfig.from_dict(config_data)
        return self.create(config)
    
    def create_from_yaml(self, yaml_data: Dict) -> LLMProvider:
        """ä» YAML é…ç½®åˆ›å»º Provider"""
        provider_data = yaml_data.copy()
        
        provider_type = ProviderType(provider_data.get('provider', 'openai'))
        
        api_key_env_map = {
            'openai': 'OPENAI_API_KEY',
            'anthropic': 'ANTHROPIC_API_KEY',
            'deepseek': 'DEEPSEEK_API_KEY',
            'groq': 'GROQ_API_KEY',
            'kimi': 'KIMI_API_KEY',
            'minimax': 'MINIMAX_API_KEY',
            'qwen': 'DASHSCOPE_API_KEY',
        }
        
        env_key = api_key_env_map.get(provider_data.get('provider', '').lower(), '')
        
        if not provider_data.get('api_key') and env_key:
            provider_data['api_key'] = os.getenv(env_key)
        
        return self.create(LLMConfig(
            provider=provider_type,
            model=provider_data.get('model', self.PROVIDERS.get(
                provider_data.get('provider', 'openai'), ProviderInfo(
                    type=provider_type, name="", description=""
                )
            ).default_model),
            api_key=provider_data.get('api_key'),
            base_url=provider_data.get('base_url'),
            max_tokens=provider_data.get('max_tokens', 4096),
            temperature=provider_data.get('temperature', 0.7),
            timeout=provider_data.get('timeout', 60.0),
            max_retries=provider_data.get('max_retries', 3),
            extra_params=provider_data.get('extra_params', {})
        ))
    
    async def create_and_initialize(self, config: LLMConfig) -> LLMProvider:
        """åˆ›å»ºå¹¶åˆå§‹åŒ– Provider"""
        provider = self.create(config)
        await provider.initialize()
        
        provider_id = f"{config.provider.value}:{config.model}"
        self._active_providers[provider_id] = provider
        
        if self._default_provider is None:
            self._default_provider = provider_id
        
        return provider
    
    async def shutdown_all(self):
        """å…³é—­æ‰€æœ‰ Provider"""
        for provider_id, provider in self._active_providers.items():
            try:
                await provider.shutdown()
                logger.info(f"Shutdown provider: {provider_id}")
            except Exception as e:
                logger.error(f"Failed to shutdown {provider_id}: {e}")
        
        self._active_providers.clear()
    
    async def get_provider(self, provider_id: str) -> Optional[LLMProvider]:
        """è·å– Provider"""
        return self._active_providers.get(provider_id)
    
    async def get_default(self) -> Optional[LLMProvider]:
        """è·å–é»˜è®¤ Provider"""
        if self._default_provider:
            return self._active_providers.get(self._default_provider)
        return None
    
    async def switch_provider(self, provider_id: str) -> bool:
        """åˆ‡æ¢é»˜è®¤ Provider"""
        if provider_id in self._active_providers:
            self._default_provider = provider_id
            logger.info(f"Switched to provider: {provider_id}")
            return True
        return False
    
    def list_providers(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰ Provider é…ç½®"""
        return [
            {
                'id': ptype,
                'name': info.name,
                'description': info.description,
                'requires_api_key': info.requires_api_key,
                'local': info.local,
                'default_model': info.default_model,
                'active': any(
                    cfg.provider.value == ptype
                    for cfg in self._active_providers.values()
                )
            }
            for ptype, info in self.PROVIDERS.items()
        ]
    
    def get_provider_info(self, provider_type: str) -> Optional[ProviderInfo]:
        """è·å– Provider ä¿¡æ¯"""
        return self.PROVIDERS.get(provider_type)
    
    def get_chinese_providers(self) -> List[ProviderInfo]:
        """è·å–ä¸­å›½æ¨¡å‹ Provider"""
        return [
            self.PROVIDERS[p]
            for p in ['deepseek', 'kimi', 'minimax', 'qwen']
        ]
    
    def get_local_providers(self) -> List[ProviderInfo]:
        """è·å–æœ¬åœ°æ¨¡å‹ Provider"""
        return [
            info for info in self.PROVIDERS.values()
            if info.local
        ]


# å…¨å±€å·¥å‚å®ä¾‹
_factory: Optional[LLMProviderFactory] = None


def get_factory() -> LLMProviderFactory:
    """è·å–å…¨å±€å·¥å‚"""
    global _factory
    if _factory is None:
        _factory = LLMProviderFactory()
    return _factory


def create_provider(config: LLMConfig) -> LLMProvider:
    """ä¾¿æ·åˆ›å»ºå‡½æ•°"""
    return get_factory().create(config)

    def create_mock(self, model: str = "mock-model") -> 'MockProvider':
        """
        åˆ›å»º Mock Provider (ç”¨äºæµ‹è¯•)
        
        Args:
            model: æ¨¡å‹åç§°
        
        Returns:
            MockProvider å®ä¾‹
        """
        from .mock_provider import MockProvider
        config = LLMConfig(
            provider="mock",
            model=model,
            api_key="mock-key"
        )
        return MockProvider(config)
